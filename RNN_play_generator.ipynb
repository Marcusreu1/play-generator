{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6k1XR4wyloyF0n9GwSkj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marcusreu1/play-generator/blob/main/RNN_play_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#import libraries"
      ],
      "metadata": {
        "id": "v_T8Tj8_TNM9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9ZKmJ59Qa4J",
        "outputId": "58eaa8ff-a33c-4d5c-ca9f-a76bc021ceff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dataset"
      ],
      "metadata": {
        "id": "yUf3WzGRT_2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "g03bMmjnUBvd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##load your own dataset from your files"
      ],
      "metadata": {
        "id": "bSaWkL4VUT-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#path_to_file=list(files.upload().keys())[0]"
      ],
      "metadata": {
        "id": "r-XwAU05VEnz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read files"
      ],
      "metadata": {
        "id": "mAjUGpYVVsIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVDyRVzSUe67",
        "outputId": "69fda3c9-a843-4d20-b082-475bcd3f3c19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#encoding"
      ],
      "metadata": {
        "id": "G7dMECv4XCtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab= sorted(set(text))\n",
        "\n",
        "#creating a mapping from unique characters to indices\n",
        "char2idx={u:i for i, u in enumerate(vocab)}\n",
        "idx2char= np.array(vocab)\n",
        "\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int= text_to_int(text)"
      ],
      "metadata": {
        "id": "ruxJNueSXXHO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see text or encoding\n",
        "print(\"Text: \", text[:13])\n",
        "print(\"Encoded: \", text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aat3YzYzdvUy",
        "outputId": "121e562a-4a4d-490d-a456-3092a32aae82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  First Citizen\n",
            "Encoded:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#encoding to text"
      ],
      "metadata": {
        "id": "hsjCiOGhf0iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints=ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return '' .join(idx2char[ints])\n",
        "\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_7ijaNrfuvV",
        "outputId": "e24d0f0f-b7e7-485b-dd65-6a29ef3fc9a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#creating training examples"
      ],
      "metadata": {
        "id": "ocs42kArCnHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=100\n",
        "examples_per_epoch= len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset=tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "0oNuD0yu0SG5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=char_dataset.batch(seq_length+1,drop_remainder=True)"
      ],
      "metadata": {
        "id": "gPBYEfV4EKGg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "\n",
        "dataset=sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "7vIYfjroE5Pt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"input\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"Output\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deBa_sLiE6Z8",
        "outputId": "3500025d-1fdb-4414-a388-415562d8926e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "input\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "Output\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "input\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "Output\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "VOCAB_SIZE=len(vocab)\n",
        "EMBEDDING_DIM= 256\n",
        "RNN_UNITS=1024\n",
        "\n",
        "BUFFER_SIZE=10000\n",
        "data= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "DqSOhGs-G3Vd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#building the model"
      ],
      "metadata": {
        "id": "OmPZDFnxJrmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size,None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                         return_sequences=True,\n",
        "                         stateful=True,\n",
        "                         recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "])\n",
        "  return model\n",
        "\n",
        "\n",
        "model=build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToEon59AJvk9",
        "outputId": "4bde3604-5167-4067-8666-705f3c0f8ad2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5330241 (20.33 MB)\n",
            "Trainable params: 5330241 (20.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#creating loss function"
      ],
      "metadata": {
        "id": "EBLM3eeGC2SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"#(batch_size, sequence_length,vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aUk_H1lZB1m",
        "outputId": "c41177c8-8cfb-4ca3-fdea-74700e6bb51a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) #(batch_size, sequence_length,vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uROn62gkaSUm",
        "outputId": "5fa3dfac-8b18-4bb5-c06e-0b7105d895a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 1.70593872e-03  5.46026696e-03  2.92965258e-03 ...  4.09210566e-03\n",
            "   -1.31352688e-03  6.82836398e-03]\n",
            "  [-1.96181657e-03  4.23642201e-03  1.31569069e-03 ...  1.73984165e-03\n",
            "   -2.33781477e-03  1.67514686e-03]\n",
            "  [-5.54576516e-04  2.71998253e-03  4.24641464e-03 ...  1.50886434e-03\n",
            "   -4.46689408e-03 -5.52857993e-04]\n",
            "  ...\n",
            "  [ 4.16014250e-03 -3.59564344e-03  9.64214560e-04 ...  4.56542335e-03\n",
            "   -8.92869313e-04  2.79668346e-03]\n",
            "  [ 3.97024164e-03  1.73156848e-03  5.82224084e-03 ...  7.69527582e-03\n",
            "   -8.74813937e-04  8.02928861e-03]\n",
            "  [ 3.71463574e-03 -2.39651417e-04  8.04606639e-03 ...  6.81372080e-03\n",
            "   -1.77982205e-03  2.73105921e-03]]\n",
            "\n",
            " [[-1.83230988e-03  2.04336178e-03  1.40121754e-03 ...  8.14289227e-03\n",
            "   -5.01889782e-03  1.50499516e-03]\n",
            "  [ 4.39304509e-04  7.06568453e-03  3.04970890e-03 ...  1.11275073e-02\n",
            "   -5.62721677e-03  7.67432060e-03]\n",
            "  [-1.06390961e-03  9.73212998e-03 -1.71539024e-03 ...  1.23288995e-02\n",
            "   -4.59532905e-03  5.51881688e-03]\n",
            "  ...\n",
            "  [-5.15212538e-03  5.67539176e-03  2.29803193e-03 ...  5.71924588e-03\n",
            "   -3.05907102e-03  6.13051746e-03]\n",
            "  [-8.21883976e-03  1.98278716e-03  4.21953853e-04 ...  1.23488707e-02\n",
            "   -8.79539363e-03  7.36963935e-03]\n",
            "  [-9.83068626e-03 -1.88313634e-03 -3.67773697e-04 ...  1.38728805e-02\n",
            "   -8.21764115e-03  5.92224393e-03]]\n",
            "\n",
            " [[-4.90091462e-03  1.13255694e-04 -9.65915387e-05 ...  3.39342561e-03\n",
            "   -4.62112995e-03 -1.99596258e-03]\n",
            "  [-2.33133510e-03 -1.71570946e-03 -7.55231129e-04 ...  4.33048978e-03\n",
            "   -7.41199870e-03 -1.70763687e-03]\n",
            "  [ 8.89248215e-04 -3.05253593e-03 -3.51685751e-03 ...  3.81858880e-03\n",
            "   -7.05504045e-03 -4.51535592e-03]\n",
            "  ...\n",
            "  [ 2.28647632e-03 -6.57767197e-03  2.49154819e-03 ...  6.80749025e-03\n",
            "   -9.82451951e-04 -1.35764824e-02]\n",
            "  [ 1.15719135e-03 -5.76970913e-03  5.04827034e-03 ...  6.15072343e-03\n",
            "   -3.52780847e-03 -1.34672392e-02]\n",
            "  [-4.64275107e-03 -5.00594173e-03  4.09454107e-03 ...  4.06253152e-03\n",
            "   -4.41069761e-03 -1.49858026e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 6.98808255e-03  4.07875516e-04  2.57977605e-04 ...  4.09990456e-03\n",
            "   -1.71992427e-03 -1.71685102e-03]\n",
            "  [ 6.14587916e-03 -6.55662036e-04  2.65614991e-03 ...  3.46689019e-03\n",
            "   -4.03551431e-03  6.62175473e-03]\n",
            "  [ 5.44692390e-03 -4.47478564e-03  3.50923487e-03 ...  1.82541553e-05\n",
            "   -5.63139515e-03  5.39678056e-03]\n",
            "  ...\n",
            "  [ 1.33701917e-02 -2.10750476e-03  4.00025025e-03 ...  1.06003713e-02\n",
            "   -1.75710255e-03 -6.64867228e-04]\n",
            "  [ 6.40723156e-03 -3.03918403e-03  2.46078987e-03 ...  2.49854103e-03\n",
            "    4.28787293e-03 -6.29801769e-04]\n",
            "  [ 3.06283124e-04 -3.55012901e-03  7.41523574e-04 ... -3.30755603e-03\n",
            "    8.17674398e-03 -7.32612098e-04]]\n",
            "\n",
            " [[ 2.98612821e-03  5.77095198e-04 -1.98004092e-03 ... -2.38488754e-03\n",
            "   -3.71747022e-03 -6.91281166e-03]\n",
            "  [-1.47862663e-03 -1.44584570e-03 -1.85723230e-03 ... -3.35686933e-03\n",
            "   -3.81437084e-03 -7.69146858e-03]\n",
            "  [-5.91162243e-04 -2.05810438e-03  1.34330336e-03 ... -8.98642000e-04\n",
            "   -6.75538601e-03 -8.83352943e-03]\n",
            "  ...\n",
            "  [ 4.88019222e-03 -1.06252311e-03 -6.39591366e-04 ...  6.59998693e-03\n",
            "   -5.69983432e-03 -9.15352814e-03]\n",
            "  [ 5.48096513e-03  4.34750412e-03  2.82955240e-03 ...  9.15036816e-03\n",
            "   -5.39718149e-03 -8.72017350e-04]\n",
            "  [ 1.12765487e-02  3.09729995e-03  1.62824953e-03 ...  1.07700862e-02\n",
            "   -4.61180694e-03 -2.15451280e-03]]\n",
            "\n",
            " [[-3.49121867e-04 -1.39596954e-03 -5.05202636e-03 ... -5.20278048e-03\n",
            "   -5.28099388e-03  2.84258905e-03]\n",
            "  [-2.96209333e-03 -4.61948756e-03 -6.60023000e-03 ... -1.23867788e-03\n",
            "   -2.77913467e-04  1.94307184e-04]\n",
            "  [-5.76218450e-03 -4.83791926e-04 -4.72788420e-03 ... -1.91962905e-03\n",
            "    2.70101195e-03 -2.14052526e-03]\n",
            "  ...\n",
            "  [-3.73450457e-03  4.17977152e-03 -6.85353065e-04 ... -3.60535318e-03\n",
            "   -6.71626069e-03 -5.61720133e-03]\n",
            "  [-2.13589333e-03  8.53373297e-03  1.42602809e-03 ...  2.33506691e-03\n",
            "   -4.98085702e-03  2.61666230e-03]\n",
            "  [-1.58335501e-03  2.36553000e-03  7.62548298e-05 ... -1.17776915e-04\n",
            "   -4.32647392e-03  3.34485155e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJBIwMYHan-t",
        "outputId": "83f0eddb-b642-46a7-90a1-d9d5b01b1e95"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 0.00170594  0.00546027  0.00292965 ...  0.00409211 -0.00131353\n",
            "   0.00682836]\n",
            " [-0.00196182  0.00423642  0.00131569 ...  0.00173984 -0.00233781\n",
            "   0.00167515]\n",
            " [-0.00055458  0.00271998  0.00424641 ...  0.00150886 -0.00446689\n",
            "  -0.00055286]\n",
            " ...\n",
            " [ 0.00416014 -0.00359564  0.00096421 ...  0.00456542 -0.00089287\n",
            "   0.00279668]\n",
            " [ 0.00397024  0.00173157  0.00582224 ...  0.00769528 -0.00087481\n",
            "   0.00802929]\n",
            " [ 0.00371464 -0.00023965  0.00804607 ...  0.00681372 -0.00177982\n",
            "   0.00273106]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_pred= pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mX1j-vDfcB3",
        "outputId": "c290a131-ffdd-47ce-c943-0a353698513e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 1.70593872e-03  5.46026696e-03  2.92965258e-03  5.53701632e-03\n",
            "  3.52002098e-04  7.40212505e-04 -2.61171139e-03  1.52184613e-04\n",
            "  5.21520991e-03  2.75546825e-03 -1.81522663e-03 -3.50444857e-03\n",
            " -6.65778178e-04 -1.89177436e-03  1.21774399e-04 -3.23639438e-03\n",
            " -1.14432565e-04 -3.76685406e-03  7.34490668e-03  4.56825335e-04\n",
            "  1.23989757e-03  5.12635894e-03 -2.03279499e-03 -4.87690512e-03\n",
            "  9.01867170e-04 -2.31072586e-03 -3.49775492e-03  3.62148602e-03\n",
            "  4.29686578e-03 -1.01282005e-03  1.96049409e-03 -1.61430333e-04\n",
            "  7.56166875e-03 -3.59967491e-03 -9.05461609e-03  4.97890869e-03\n",
            " -4.73952387e-03  1.28577230e-05 -3.10298847e-03 -2.48091645e-03\n",
            " -3.36558325e-04 -4.44768276e-03  1.32296328e-03  2.99261999e-03\n",
            "  4.66113118e-03 -4.61108238e-03  4.19483427e-03 -3.41579271e-03\n",
            "  7.59466668e-04  1.69871654e-03 -5.20434813e-04 -3.82753205e-04\n",
            " -2.79553467e-03 -6.21518958e-03  2.48010550e-03  6.25119172e-03\n",
            " -1.75662478e-03  5.05508156e-03 -3.93605558e-04  5.70973940e-03\n",
            " -4.55881283e-03 -2.01381627e-03  4.09210566e-03 -1.31352688e-03\n",
            "  6.82836398e-03], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices= tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "\n",
        "predicted_chars= int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NkAbglSRf-Jw",
        "outputId": "fd237063-6116-4cba-8f16-a8a8c3dbeddb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"U'wYOb3bqokq'UFb\\nbdO Px'YqFQi.mmBq,!T-AwbbAcxZn;.U'wTm\\nJZDSesFrfLO.AzvVYkQ&xR;WsHZ- 3qFBaoFqnlhN'J,F\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "uFyVWRZxiDBy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#compilar modelo"
      ],
      "metadata": {
        "id": "MZu-SPeAjMM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "metadata": {
        "id": "I1Jgtwu0ilWZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#creating checkpoints"
      ],
      "metadata": {
        "id": "K3wZRhLqj-UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir='./training_checkpoints'\n",
        "\n",
        "checkpoint_prefix= os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "W5uE2o8cj8qG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "KOW90OSSk1c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history= model.fit(data, epochs= 10, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07GzFXqsk3S7",
        "outputId": "0b6be7e9-1910-4a69-c316-74649c171131"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 19s 83ms/step - loss: 2.7858\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 16s 82ms/step - loss: 2.0860\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 15s 79ms/step - loss: 1.8225\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 1.6665\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 15s 80ms/step - loss: 1.5657\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 16s 82ms/step - loss: 1.4967\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 18s 80ms/step - loss: 1.4454\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 1.4058\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 1.3732\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 16s 81ms/step - loss: 1.3457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading the model"
      ],
      "metadata": {
        "id": "qZm1j1KXleCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "DtnN9WoilW75"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#generar texto"
      ],
      "metadata": {
        "id": "Dt3JKxSCn4Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generate=400\n",
        "\n",
        "  input_eval=[char2idx[s] for s in start_string]\n",
        "  input_eval=tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated= []\n",
        "\n",
        "  temperature=1.2\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions= model(input_eval)\n",
        "    predictions=tf.squeeze(predictions,0)\n",
        "    predictions= predictions/temperature\n",
        "    predicted_id= tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "    input_eval= tf.expand_dims([predicted_id], 0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "  return(start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "WgmHpGlun6V2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp= input(\"type a starting string \")\n",
        "print(generate_text(model, inp))"
      ],
      "metadata": {
        "id": "GmNrhiC8wxOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b0d659-c94f-45f8-ff76-134cb091331d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type a starting string hello\n",
            "hellow cry him then\n",
            ": they do your butting Baptain'd. Petry may thy ought Duke thy cry.\n",
            "Seek thou thy Abothat adiled, my ling.\n",
            "\n",
            "GLOURES:\n",
            "Yes, by yourself to do.\n",
            "Some scarkewed Sast sound to privolds.\n",
            "\n",
            "DUCHESS Onjeed's death. This, I'll cupt be ic:\n",
            "Accurdental deserved inhy blood were\n",
            "and than the entert, take your wrong; if it is exy\n",
            "grimins, Lanshouslard Ghut here reblace my\n",
            "bandal'st, drupj hence age\n"
          ]
        }
      ]
    }
  ]
}